{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026108fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1165bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data_consolidation_standardization.csv\")\n",
    "data=data.drop(labels=\"Unnamed: 0\", axis=1)\n",
    "# data_test=data.loc[data['CellID']<=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9cff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['CellID','datetime'], inplace=True)\n",
    "data_test=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4c014b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>CellID</th>\n",
       "      <th>internet</th>\n",
       "      <th>calls</th>\n",
       "      <th>sms</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.045031</td>\n",
       "      <td>-0.739046</td>\n",
       "      <td>-0.846748</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2013-11-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.074765</td>\n",
       "      <td>-0.750493</td>\n",
       "      <td>-0.865873</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2013-11-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.087136</td>\n",
       "      <td>-0.754285</td>\n",
       "      <td>-0.873567</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2013-11-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.096080</td>\n",
       "      <td>-0.757753</td>\n",
       "      <td>-0.875403</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2013-11-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.109877</td>\n",
       "      <td>-0.756706</td>\n",
       "      <td>-0.878479</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16399</th>\n",
       "      <td>2013-11-07 19:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>-0.004918</td>\n",
       "      <td>-0.064944</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16499</th>\n",
       "      <td>2013-11-07 20:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.141303</td>\n",
       "      <td>-0.239126</td>\n",
       "      <td>-0.156799</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16599</th>\n",
       "      <td>2013-11-07 21:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.231419</td>\n",
       "      <td>-0.426115</td>\n",
       "      <td>-0.262352</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16699</th>\n",
       "      <td>2013-11-07 22:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.319378</td>\n",
       "      <td>-0.600432</td>\n",
       "      <td>-0.395659</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>2013-11-07 23:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.463642</td>\n",
       "      <td>-0.677496</td>\n",
       "      <td>-0.616486</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  CellID  internet     calls       sms  longitude  \\\n",
       "0     2013-11-01 00:00:00       1 -1.045031 -0.739046 -0.846748   9.160012   \n",
       "100   2013-11-01 01:00:00       1 -1.074765 -0.750493 -0.865873   9.160012   \n",
       "200   2013-11-01 02:00:00       1 -1.087136 -0.754285 -0.873567   9.160012   \n",
       "300   2013-11-01 03:00:00       1 -1.096080 -0.757753 -0.875403   9.160012   \n",
       "400   2013-11-01 04:00:00       1 -1.109877 -0.756706 -0.878479   9.160012   \n",
       "...                   ...     ...       ...       ...       ...        ...   \n",
       "16399 2013-11-07 19:00:00     100 -0.050505 -0.004918 -0.064944   9.160606   \n",
       "16499 2013-11-07 20:00:00     100 -0.141303 -0.239126 -0.156799   9.160606   \n",
       "16599 2013-11-07 21:00:00     100 -0.231419 -0.426115 -0.262352   9.160606   \n",
       "16699 2013-11-07 22:00:00     100 -0.319378 -0.600432 -0.395659   9.160606   \n",
       "16799 2013-11-07 23:00:00     100 -0.463642 -0.677496 -0.616486   9.160606   \n",
       "\n",
       "        latitude  \n",
       "0      45.358657  \n",
       "100    45.358657  \n",
       "200    45.358657  \n",
       "300    45.358657  \n",
       "400    45.358657  \n",
       "...          ...  \n",
       "16399  45.568069  \n",
       "16499  45.568069  \n",
       "16599  45.568069  \n",
       "16699  45.568069  \n",
       "16799  45.568069  \n",
       "\n",
       "[16800 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74561ff6",
   "metadata": {},
   "source": [
    "# 根据需要选择不同的基站或者流量/语音/短信数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713a68b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     internet\n",
      "datetime                     \n",
      "2013-11-01 00:00:00 -1.045031\n",
      "2013-11-01 01:00:00 -1.074765\n",
      "2013-11-01 02:00:00 -1.087136\n",
      "2013-11-01 03:00:00 -1.096080\n",
      "2013-11-01 04:00:00 -1.109877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "# data = pd.read_csv('path_to_your_data.csv')  # 根据您的文件路径和文件名进行调整\n",
    "\n",
    "data = data_test  # 根据您的文件路径和文件名进行调整\n",
    "\n",
    "# 将时间字符串转换为pandas的datetime对象，这假设'datetime'是存储时间的列\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "\n",
    "# 对每个基站分别提取数据\n",
    "def extract_time_series(data, cell_id, feature):\n",
    "    \"\"\"\n",
    "    提取特定基站的时间序列数据。\n",
    "    Args:\n",
    "    data (DataFrame): 包含所有数据的DataFrame。\n",
    "    cell_id (int): 基站ID。\n",
    "    feature (str): 要提取的特征名，如'internet', 'calls', 'sms'。\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: 包含特定基站和特征的时间序列数据。\n",
    "    \"\"\"\n",
    "    # 过滤特定基站的数据\n",
    "    specific_data = data[data['CellID'] == cell_id][['datetime', feature]]\n",
    "    specific_data.set_index('datetime', inplace=True)\n",
    "    return specific_data\n",
    "\n",
    "# 示例：提取基站ID为1的基站的流量数据\n",
    "cell_id = 1\n",
    "feature = 'internet'\n",
    "ts_data = extract_time_series(data, cell_id, feature)\n",
    "print(ts_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e131c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-01 00:00:00</th>\n",
       "      <td>-1.045031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 01:00:00</th>\n",
       "      <td>-1.074765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 02:00:00</th>\n",
       "      <td>-1.087136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 03:00:00</th>\n",
       "      <td>-1.096080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 04:00:00</th>\n",
       "      <td>-1.109877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 19:00:00</th>\n",
       "      <td>-0.930432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 20:00:00</th>\n",
       "      <td>-0.942378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 21:00:00</th>\n",
       "      <td>-0.963610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 22:00:00</th>\n",
       "      <td>-0.975810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 23:00:00</th>\n",
       "      <td>-1.009715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     internet\n",
       "datetime                     \n",
       "2013-11-01 00:00:00 -1.045031\n",
       "2013-11-01 01:00:00 -1.074765\n",
       "2013-11-01 02:00:00 -1.087136\n",
       "2013-11-01 03:00:00 -1.096080\n",
       "2013-11-01 04:00:00 -1.109877\n",
       "...                       ...\n",
       "2013-11-07 19:00:00 -0.930432\n",
       "2013-11-07 20:00:00 -0.942378\n",
       "2013-11-07 21:00:00 -0.963610\n",
       "2013-11-07 22:00:00 -0.975810\n",
       "2013-11-07 23:00:00 -1.009715\n",
       "\n",
       "[168 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47161c82",
   "metadata": {},
   "source": [
    "# 滑动窗口构建训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96560cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window_size, predict_steps):\n",
    "    \"\"\"\n",
    "    创建滑动窗口数据。\n",
    "    Args:\n",
    "    data (Series): 输入的时间序列数据。\n",
    "    window_size (int): 滑动窗口的大小。\n",
    "    predict_steps (int): 需要预测的未来步数。\n",
    "    \n",
    "    Returns:\n",
    "    tuple: 包含特征和标签的元组。\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - predict_steps + 1):\n",
    "        X.append(data.iloc[i:(i + window_size)].values)\n",
    "        y.append(data.iloc[i + window_size:(i + window_size + predict_steps)].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 使用示例\n",
    "window_size = 6\n",
    "predict_steps = 3\n",
    "X, y = create_sequences(ts_data[feature], window_size, predict_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "538719cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取出时间序列\n",
    "internet_series = grouped['internet']\n",
    "calls_series = grouped['calls']\n",
    "sms_series = grouped['sms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6698399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08456512",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "grouped_scaled = scaler.fit_transform(grouped[['internet', 'calls', 'sms']])\n",
    "grouped_scaled = pd.DataFrame(grouped_scaled, columns=['internet', 'calls', 'sms'], index=grouped.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1111f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取流量数据\n",
    "internet_series = grouped_scaled['internet'].values\n",
    "\n",
    "# 创建滑动窗口数据\n",
    "window_size = 6\n",
    "predict_steps = 3  # 可调整为需要预测的步数\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(len(internet_series) - window_size - predict_steps + 1):\n",
    "    X.append(internet_series[i:i + window_size])\n",
    "    y.append(internet_series[i + window_size:i + window_size + predict_steps])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 调整形状以符合PyTorch LSTM的输入 (batch, seq_len, feature)\n",
    "X = np.reshape(X, (X.shape[0], window_size, 1))\n",
    "y = np.reshape(y, (y.shape[0], predict_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e04665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac579c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 转换为torch张量\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 创建DataLoaders\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90da1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = self.fc(hn[-1])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de79dce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.9136529862880707\n",
      "Epoch 2/50, Loss: 0.7189526557922363\n",
      "Epoch 3/50, Loss: 0.5431229472160339\n",
      "Epoch 4/50, Loss: 0.3424280658364296\n",
      "Epoch 5/50, Loss: 0.20153964683413506\n",
      "Epoch 6/50, Loss: 0.17052636668086052\n",
      "Epoch 7/50, Loss: 0.15099605917930603\n",
      "Epoch 8/50, Loss: 0.13519935123622417\n",
      "Epoch 9/50, Loss: 0.11088074557483196\n",
      "Epoch 10/50, Loss: 0.11560635268688202\n",
      "Epoch 11/50, Loss: 0.0985585618764162\n",
      "Epoch 12/50, Loss: 0.09771551378071308\n",
      "Epoch 13/50, Loss: 0.09349546860903502\n",
      "Epoch 14/50, Loss: 0.09523035772144794\n",
      "Epoch 15/50, Loss: 0.08879561722278595\n",
      "Epoch 16/50, Loss: 0.08547256514430046\n",
      "Epoch 17/50, Loss: 0.08072415553033352\n",
      "Epoch 18/50, Loss: 0.07806734461337328\n",
      "Epoch 19/50, Loss: 0.08585909474641085\n",
      "Epoch 20/50, Loss: 0.07124293129891157\n",
      "Epoch 21/50, Loss: 0.07401868514716625\n",
      "Epoch 22/50, Loss: 0.07204100675880909\n",
      "Epoch 23/50, Loss: 0.06915511842817068\n",
      "Epoch 24/50, Loss: 0.06554146576672792\n",
      "Epoch 25/50, Loss: 0.06607075873762369\n",
      "Epoch 26/50, Loss: 0.06860547140240669\n",
      "Epoch 27/50, Loss: 0.07289992086589336\n",
      "Epoch 28/50, Loss: 0.06657753605395555\n",
      "Epoch 29/50, Loss: 0.0592317720875144\n",
      "Epoch 30/50, Loss: 0.05649534799158573\n",
      "Epoch 31/50, Loss: 0.060248976573348045\n",
      "Epoch 32/50, Loss: 0.055294301360845566\n",
      "Epoch 33/50, Loss: 0.05431629158556461\n",
      "Epoch 34/50, Loss: 0.055469103157520294\n",
      "Epoch 35/50, Loss: 0.06520477728918195\n",
      "Epoch 36/50, Loss: 0.06032394710928202\n",
      "Epoch 37/50, Loss: 0.06263795308768749\n",
      "Epoch 38/50, Loss: 0.05008149240165949\n",
      "Epoch 39/50, Loss: 0.0566076198592782\n",
      "Epoch 40/50, Loss: 0.05390113312751055\n",
      "Epoch 41/50, Loss: 0.05141260474920273\n",
      "Epoch 42/50, Loss: 0.050763451494276524\n",
      "Epoch 43/50, Loss: 0.04731512535363436\n",
      "Epoch 44/50, Loss: 0.04882787261158228\n",
      "Epoch 45/50, Loss: 0.05277697276324034\n",
      "Epoch 46/50, Loss: 0.04900903068482876\n",
      "Epoch 47/50, Loss: 0.04554848000407219\n",
      "Epoch 48/50, Loss: 0.040209139697253704\n",
      "Epoch 49/50, Loss: 0.039456982631236315\n",
      "Epoch 50/50, Loss: 0.0409339782781899\n"
     ]
    }
   ],
   "source": [
    "# 模型初始化\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMModel(input_dim=1, hidden_dim=50, num_layers=1, output_dim=predict_steps).to(device)\n",
    "\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 模型训练\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315ac83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
