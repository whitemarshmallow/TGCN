{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026108fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1165bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data_consolidation_standardization.csv\")\n",
    "data=data.drop(labels=\"Unnamed: 0\", axis=1)\n",
    "# data_test=data.loc[data['CellID']<=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab9cff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['CellID','datetime'], inplace=True)\n",
    "data_test=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4c014b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>CellID</th>\n",
       "      <th>internet</th>\n",
       "      <th>calls</th>\n",
       "      <th>sms</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.045031</td>\n",
       "      <td>-0.739046</td>\n",
       "      <td>-0.846748</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2013-11-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.074765</td>\n",
       "      <td>-0.750493</td>\n",
       "      <td>-0.865873</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2013-11-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.087136</td>\n",
       "      <td>-0.754285</td>\n",
       "      <td>-0.873567</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2013-11-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.096080</td>\n",
       "      <td>-0.757753</td>\n",
       "      <td>-0.875403</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2013-11-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.109877</td>\n",
       "      <td>-0.756706</td>\n",
       "      <td>-0.878479</td>\n",
       "      <td>9.160012</td>\n",
       "      <td>45.358657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16399</th>\n",
       "      <td>2013-11-07 19:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>-0.004918</td>\n",
       "      <td>-0.064944</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16499</th>\n",
       "      <td>2013-11-07 20:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.141303</td>\n",
       "      <td>-0.239126</td>\n",
       "      <td>-0.156799</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16599</th>\n",
       "      <td>2013-11-07 21:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.231419</td>\n",
       "      <td>-0.426115</td>\n",
       "      <td>-0.262352</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16699</th>\n",
       "      <td>2013-11-07 22:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.319378</td>\n",
       "      <td>-0.600432</td>\n",
       "      <td>-0.395659</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>2013-11-07 23:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.463642</td>\n",
       "      <td>-0.677496</td>\n",
       "      <td>-0.616486</td>\n",
       "      <td>9.160606</td>\n",
       "      <td>45.568069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  CellID  internet     calls       sms  longitude  \\\n",
       "0      2013-11-01 00:00:00       1 -1.045031 -0.739046 -0.846748   9.160012   \n",
       "100    2013-11-01 01:00:00       1 -1.074765 -0.750493 -0.865873   9.160012   \n",
       "200    2013-11-01 02:00:00       1 -1.087136 -0.754285 -0.873567   9.160012   \n",
       "300    2013-11-01 03:00:00       1 -1.096080 -0.757753 -0.875403   9.160012   \n",
       "400    2013-11-01 04:00:00       1 -1.109877 -0.756706 -0.878479   9.160012   \n",
       "...                    ...     ...       ...       ...       ...        ...   \n",
       "16399  2013-11-07 19:00:00     100 -0.050505 -0.004918 -0.064944   9.160606   \n",
       "16499  2013-11-07 20:00:00     100 -0.141303 -0.239126 -0.156799   9.160606   \n",
       "16599  2013-11-07 21:00:00     100 -0.231419 -0.426115 -0.262352   9.160606   \n",
       "16699  2013-11-07 22:00:00     100 -0.319378 -0.600432 -0.395659   9.160606   \n",
       "16799  2013-11-07 23:00:00     100 -0.463642 -0.677496 -0.616486   9.160606   \n",
       "\n",
       "        latitude  \n",
       "0      45.358657  \n",
       "100    45.358657  \n",
       "200    45.358657  \n",
       "300    45.358657  \n",
       "400    45.358657  \n",
       "...          ...  \n",
       "16399  45.568069  \n",
       "16499  45.568069  \n",
       "16599  45.568069  \n",
       "16699  45.568069  \n",
       "16799  45.568069  \n",
       "\n",
       "[16800 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74561ff6",
   "metadata": {},
   "source": [
    "# 根据需要选择不同的基站或者流量/语音/短信数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "713a68b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     internet\n",
      "datetime                     \n",
      "2013-11-01 00:00:00 -1.045031\n",
      "2013-11-01 01:00:00 -1.074765\n",
      "2013-11-01 02:00:00 -1.087136\n",
      "2013-11-01 03:00:00 -1.096080\n",
      "2013-11-01 04:00:00 -1.109877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "# data = pd.read_csv('path_to_your_data.csv')  # 根据您的文件路径和文件名进行调整\n",
    "\n",
    "data = data_test  # 根据您的文件路径和文件名进行调整\n",
    "\n",
    "# 将时间字符串转换为pandas的datetime对象，这假设'datetime'是存储时间的列\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "\n",
    "# 对每个基站分别提取数据\n",
    "def extract_time_series(data, cell_id, feature):\n",
    "    \"\"\"\n",
    "    提取特定基站的时间序列数据。\n",
    "    Args:\n",
    "    data (DataFrame): 包含所有数据的DataFrame。\n",
    "    cell_id (int): 基站ID。\n",
    "    feature (str): 要提取的特征名，如'internet', 'calls', 'sms'。\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: 包含特定基站和特征的时间序列数据。\n",
    "    \"\"\"\n",
    "    # 过滤特定基站的数据\n",
    "    specific_data = data[data['CellID'] == cell_id][['datetime', feature]]\n",
    "    specific_data.set_index('datetime', inplace=True)\n",
    "    return specific_data\n",
    "\n",
    "# 示例：提取基站ID为1的基站的流量数据\n",
    "cell_id = 1\n",
    "feature = 'internet'\n",
    "ts_data = extract_time_series(data, cell_id, feature)\n",
    "print(ts_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e131c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-01 00:00:00</th>\n",
       "      <td>-1.045031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 01:00:00</th>\n",
       "      <td>-1.074765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 02:00:00</th>\n",
       "      <td>-1.087136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 03:00:00</th>\n",
       "      <td>-1.096080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 04:00:00</th>\n",
       "      <td>-1.109877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 19:00:00</th>\n",
       "      <td>-0.930432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 20:00:00</th>\n",
       "      <td>-0.942378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 21:00:00</th>\n",
       "      <td>-0.963610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 22:00:00</th>\n",
       "      <td>-0.975810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-07 23:00:00</th>\n",
       "      <td>-1.009715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     internet\n",
       "datetime                     \n",
       "2013-11-01 00:00:00 -1.045031\n",
       "2013-11-01 01:00:00 -1.074765\n",
       "2013-11-01 02:00:00 -1.087136\n",
       "2013-11-01 03:00:00 -1.096080\n",
       "2013-11-01 04:00:00 -1.109877\n",
       "...                       ...\n",
       "2013-11-07 19:00:00 -0.930432\n",
       "2013-11-07 20:00:00 -0.942378\n",
       "2013-11-07 21:00:00 -0.963610\n",
       "2013-11-07 22:00:00 -0.975810\n",
       "2013-11-07 23:00:00 -1.009715\n",
       "\n",
       "[168 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47161c82",
   "metadata": {},
   "source": [
    "# 滑动窗口构建数据集和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96560cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window_size, predict_steps):\n",
    "    \"\"\"\n",
    "    创建滑动窗口数据。\n",
    "    Args:\n",
    "    data (Series): 输入的时间序列数据。\n",
    "    window_size (int): 滑动窗口的大小。\n",
    "    predict_steps (int): 需要预测的未来步数。\n",
    "    \n",
    "    Returns:\n",
    "    tuple: 包含特征和标签的元组。\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - predict_steps + 1):\n",
    "        X.append(data.iloc[i:(i + window_size)].values)\n",
    "        y.append(data.iloc[i + window_size:(i + window_size + predict_steps)].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 使用示例\n",
    "window_size = 6\n",
    "predict_steps = 3\n",
    "X, y = create_sequences(ts_data[feature], window_size, predict_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8841cf",
   "metadata": {},
   "source": [
    "# 构建训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e9064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 转换数据为Tensor\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)  # 增加一个维度以适应LSTM输入要求\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f4e16",
   "metadata": {},
   "source": [
    "# 定义LSTM模型并初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94d11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = self.fc(hn[-1])\n",
    "        return out\n",
    "\n",
    "# 初始化模型\n",
    "input_dim = 1  # 因为增加了一个维度，每个时间步只有一个特征\n",
    "hidden_dim = 50\n",
    "num_layers = 1\n",
    "output_dim = predict_steps  # 预测步数\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb3198",
   "metadata": {},
   "source": [
    "# 训练和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dde93679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.029972142714541405\n",
      "Epoch 2/50, Loss: 0.029799905605614185\n",
      "Epoch 3/50, Loss: 0.00946376723004505\n",
      "Epoch 4/50, Loss: 0.007438401458784938\n",
      "Epoch 5/50, Loss: 0.007602635072544217\n",
      "Epoch 6/50, Loss: 0.0048556438414379954\n",
      "Epoch 7/50, Loss: 0.0055335917277261615\n",
      "Epoch 8/50, Loss: 0.003371546568814665\n",
      "Epoch 9/50, Loss: 0.00429895258275792\n",
      "Epoch 10/50, Loss: 0.003271350229624659\n",
      "Epoch 11/50, Loss: 0.0035784626961685717\n",
      "Epoch 12/50, Loss: 0.003761613683309406\n",
      "Epoch 13/50, Loss: 0.0033117233542725444\n",
      "Epoch 14/50, Loss: 0.0033640293404459953\n",
      "Epoch 15/50, Loss: 0.003135216946247965\n",
      "Epoch 16/50, Loss: 0.003201183571945876\n",
      "Epoch 17/50, Loss: 0.0031187618151307106\n",
      "Epoch 18/50, Loss: 0.00314393820008263\n",
      "Epoch 19/50, Loss: 0.0031374480458907783\n",
      "Epoch 20/50, Loss: 0.0031213033362291753\n",
      "Epoch 21/50, Loss: 0.0030768002616241574\n",
      "Epoch 22/50, Loss: 0.0031566359102725983\n",
      "Epoch 23/50, Loss: 0.0031896306318230927\n",
      "Epoch 24/50, Loss: 0.003218326542992145\n",
      "Epoch 25/50, Loss: 0.0030937873525545\n",
      "Epoch 26/50, Loss: 0.0031788633787073195\n",
      "Epoch 27/50, Loss: 0.0032162501593120396\n",
      "Epoch 28/50, Loss: 0.0032286879140883684\n",
      "Epoch 29/50, Loss: 0.0031252221087925136\n",
      "Epoch 30/50, Loss: 0.003110199759248644\n",
      "Epoch 31/50, Loss: 0.0030356310307979584\n",
      "Epoch 32/50, Loss: 0.0030412215273827314\n",
      "Epoch 33/50, Loss: 0.0030695092864334583\n",
      "Epoch 34/50, Loss: 0.0031479228055104613\n",
      "Epoch 35/50, Loss: 0.003105251817032695\n",
      "Epoch 36/50, Loss: 0.003017714712768793\n",
      "Epoch 37/50, Loss: 0.0030221582273952663\n",
      "Epoch 38/50, Loss: 0.0030344216502271593\n",
      "Epoch 39/50, Loss: 0.0029979939572513103\n",
      "Epoch 40/50, Loss: 0.0030012723291292787\n",
      "Epoch 41/50, Loss: 0.002980337478220463\n",
      "Epoch 42/50, Loss: 0.0030882121063768864\n",
      "Epoch 43/50, Loss: 0.0030751025769859552\n",
      "Epoch 44/50, Loss: 0.002959921082947403\n",
      "Epoch 45/50, Loss: 0.003051183302886784\n",
      "Epoch 46/50, Loss: 0.0032066882704384625\n",
      "Epoch 47/50, Loss: 0.0029644002788700163\n",
      "Epoch 48/50, Loss: 0.003004643600434065\n",
      "Epoch 49/50, Loss: 0.0030065645405557007\n",
      "Epoch 50/50, Loss: 0.003055848355870694\n",
      "Test MSE: 0.0025411578826606274\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    print(f'Test MSE: {total_loss/len(test_loader)}')\n",
    "\n",
    "evaluate_model(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315ac83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
